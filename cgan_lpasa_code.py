# -*- coding: utf-8 -*-
"""CGAN_LPASA_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dfu8MYRuiYkhHaPk80Bxfcv75jsMwZBJ

Training
"""

import os
import numpy as np
from typing import Tuple

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision.utils import save_image
from torchvision import transforms
from torchvision.models import vgg19
from PIL import Image
from skimage.metrics import peak_signal_noise_ratio as compare_psnr, structural_similarity as compare_ssim

# ------------------------------------------------------------------------------------
# Speed / memory knobs
# ------------------------------------------------------------------------------------
os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')

# ------------------------------------------------------------------------------------
# Utils
# ------------------------------------------------------------------------------------

def init_weights(m):
    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
        nn.init.kaiming_normal_(m.weight, a=0.2, mode='fan_in', nonlinearity='leaky_relu')
        if m.bias is not None:
            nn.init.zeros_(m.bias)

# ------------------------------------------------------------------------------------
# Core blocks (Residual block replaces Dense residual block everywhere)
# ------------------------------------------------------------------------------------
class ResidualBlock(nn.Module):
    """Simple residual block: Conv -> ReLU -> Conv, residual add."""
    def __init__(self, ch: int):
        super().__init__()
        self.conv1 = nn.Conv2d(ch, ch, 3, 1, 1)
        self.conv2 = nn.Conv2d(ch, ch, 3, 1, 1)
        self.act = nn.ReLU(inplace=True)

    def forward(self, x):
        out = self.act(self.conv1(x))
        out = self.conv2(out)
        return x + out

class LearnableSelfAttention(nn.Module):
    """Lightweight self-attention over HxW tokens with learnable scale.
       Operates at 1/4 spatial scale to keep memory in check (assumes input is already downsampled)."""
    def __init__(self, channels: int, reduction: int = 8):
        super().__init__()
        red = max(1, channels // reduction)
        self.q = nn.Conv2d(channels, red, 1)
        self.k = nn.Conv2d(channels, red, 1)
        self.v = nn.Conv2d(channels, channels, 1)
        self.gamma = nn.Parameter(torch.tensor(0.1))
        self.scale = red ** -0.5

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, C, H, W = x.shape
        N = H * W
        q = self.q(x).view(B, -1, N).transpose(1, 2)      # [B, N, d]
        k = self.k(x).view(B, -1, N)                       # [B, d, N]
        v = self.v(x).view(B, C, N).transpose(1, 2)        # [B, N, C]
        attn = torch.softmax((q @ k) * self.scale, dim=-1) # [B, N, N]
        out = attn @ v                                     # [B, N, C]
        out = out.transpose(1, 2).view(B, C, H, W)
        return self.gamma * out + x

# ------------------------------------------------------------------------------------
# Generator & Discriminator
# ------------------------------------------------------------------------------------
class AdvancedAttentionGenerator(nn.Module):
    def __init__(self, in_channels: int = 3, out_channels: int = 3, base: int = 64):
        super().__init__()
        # Encoders
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_channels, base, 3, 1, 1), nn.ReLU(inplace=True)
        )
        self.enc2 = nn.Sequential(
            nn.Conv2d(base, base * 2, 4, 2, 1), nn.ReLU(inplace=True)   # 1/2
        )
        self.enc3 = nn.Sequential(
            nn.Conv2d(base * 2, base * 4, 4, 2, 1), nn.ReLU(inplace=True)  # 1/4
        )
        # Bottleneck (Residual blocks + Attention at 1/4 scale)
        self.bottleneck = nn.Sequential(
            ResidualBlock(base * 4),
            LearnableSelfAttention(base * 4),
            ResidualBlock(base * 4),
        )
        # Decoders
        self.dec1 = nn.ConvTranspose2d(base * 4, base * 2, 4, 2, 1)
        self.dec2 = nn.ConvTranspose2d(base * 2, base, 4, 2, 1)
        self.dec3 = nn.Conv2d(base, out_channels, 3, 1, 1)
        self.apply(init_weights)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        e1 = self.enc1(x)
        e2 = self.enc2(e1)
        e3 = self.enc3(e2)
        z = self.bottleneck(e3)
        d1 = self.dec1(z) + e2
        d2 = self.dec2(d1) + e1
        out = self.dec3(d2)
        return torch.sigmoid(out)  # constrain to [0,1]

class LightweightDiscriminator(nn.Module):
    """PatchGAN-style discriminator operating on 6-channel pairs [hazy, target]."""
    def __init__(self, in_channels: int = 6):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_channels, 64, 4, 2, 1), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1), nn.InstanceNorm2d(128), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1), nn.InstanceNorm2d(256), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, 4, 1, 1), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, 4, 1, 1)
        )
        self.apply(init_weights)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)

# ------------------------------------------------------------------------------------
# Dataset (paired)
# ------------------------------------------------------------------------------------
class HazyDataset(Dataset):
    def __init__(self, hazy_dir: str, clear_dir: str, transform=None):
        self.hazy_paths = sorted([os.path.join(hazy_dir, f) for f in os.listdir(hazy_dir)
                                  if f.lower().endswith((".png", ".jpg", ".jpeg"))])
        self.clear_paths = sorted([os.path.join(clear_dir, f) for f in os.listdir(clear_dir)
                                   if f.lower().endswith((".png", ".jpg", ".jpeg"))])
        if len(self.hazy_paths) != len(self.clear_paths):
            raise ValueError(f"Mismatch in #images: hazy={len(self.hazy_paths)} vs clear={len(self.clear_paths)}")
        self.transform = transform

    def __len__(self):
        return len(self.hazy_paths)

    def __getitem__(self, idx):
        hazy = Image.open(self.hazy_paths[idx]).convert('RGB')
        clear = Image.open(self.clear_paths[idx]).convert('RGB')
        if self.transform:
            hazy = self.transform(hazy)
            clear = self.transform(clear)
        return hazy, clear

# ------------------------------------------------------------------------------------
# Losses
# ------------------------------------------------------------------------------------
class VGGFeatureExtractor(nn.Module):
    def __init__(self, layers: int = 16, device: str = 'cpu'):
        super().__init__()
        vgg = vgg19(weights='IMAGENET1K_V1').features[:layers].eval()
        for p in vgg.parameters():
            p.requires_grad_(False)
        self.vgg = vgg.to(device)
        # Register mean/std for ImageNet normalization inside the module
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
        self.register_buffer('mean', mean)
        self.register_buffer('std', std)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Expect x in [0,1]; normalize to ImageNet stats
        x = (x - self.mean) / self.std
        return self.vgg(x)

class SSIMLossTorch(nn.Module):
    """Differentiable SSIM loss (1-SSIM) implemented in torch."""
    def __init__(self, window_size: int = 7, channel: int = 3):
        super().__init__()
        assert window_size % 2 == 1, "window_size must be odd"
        self.window_size = window_size
        self.channel = channel
        # Create Gaussian window
        gauss = torch.tensor([np.exp(-(x - window_size//2)**2 / float(2*1.5**2)) for x in range(window_size)])
        gauss = gauss / gauss.sum()
        window = gauss[:, None] @ gauss[None, :]
        window = window.float().unsqueeze(0).unsqueeze(0)
        self.register_buffer('window', window)

    def _filter(self, img: torch.Tensor) -> torch.Tensor:
        window = self.window.expand(img.size(1), 1, self.window_size, self.window_size)
        return F.conv2d(img, window, padding=self.window_size//2, groups=img.size(1))

    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
        C1 = 0.01 ** 2
        C2 = 0.03 ** 2
        mu_x = self._filter(x)
        mu_y = self._filter(y)
        sigma_x = self._filter(x * x) - mu_x * mu_x
        sigma_y = self._filter(y * y) - mu_y * mu_y
        sigma_xy = self._filter(x * y) - mu_x * mu_y
        ssim_map = ((2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)) / ((mu_x**2 + mu_y**2 + C1) * (sigma_x + sigma_y + C2))
        return 1 - ssim_map.clamp(min=0, max=1).mean()

# Hinge GAN losses

def d_hinge_loss(real_logits: torch.Tensor, fake_logits: torch.Tensor) -> torch.Tensor:
    return F.relu(1 - real_logits).mean() + F.relu(1 + fake_logits).mean()

def g_hinge_loss(fake_logits: torch.Tensor) -> torch.Tensor:
    return -fake_logits.mean()

# Full generator loss
class GeneratorLoss(nn.Module):
    def __init__(self, vgg_extractor: VGGFeatureExtractor, w_l1=120.0, w_perc=100.0, w_ssim=70.0, w_adv=1.0, w_entropy=1.0):
        super().__init__()
        self.vgg = vgg_extractor
        self.l1 = nn.L1Loss()
        self.ssim = SSIMLossTorch(window_size=7)
        self.w_l1, self.w_perc, self.w_ssim, self.w_adv, self.w_entropy = w_l1, w_perc, w_ssim, w_adv, w_entropy

    @staticmethod
    def entropy_regularization(x: torch.Tensor) -> torch.Tensor:
        p = torch.clamp(x, 1e-6, 1-1e-6)
        return -(p * torch.log(p) + (1 - p) * torch.log(1 - p)).mean()

    def forward(self, hazy: torch.Tensor, clear: torch.Tensor, dehazed: torch.Tensor, D: nn.Module) -> torch.Tensor:
        # Content & Perceptual
        l1 = self.l1(dehazed, clear)
        perc = self.l1(self.vgg(dehazed), self.vgg(clear))
        ssim = self.ssim(dehazed, clear)
        entropy = self.entropy_regularization(dehazed)
        # Adversarial (generator wants D to think fake is real)
        fake_logits = D(torch.cat([hazy, dehazed], dim=1))
        adv = g_hinge_loss(fake_logits)
        total = self.w_l1 * l1 + self.w_perc * perc + self.w_ssim * ssim + self.w_entropy * entropy + self.w_adv * adv
        return total, {
            'l1': l1.detach(), 'perc': perc.detach(), 'ssim': (1-ssim).detach(), 'entropy': entropy.detach(), 'adv': (-adv).detach()
        }

# ------------------------------------------------------------------------------------
# Training & Validation
# ------------------------------------------------------------------------------------
@torch.no_grad()
def validate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:
    model.eval()
    psnrs, ssims = [], []
    for hazy, clear in loader:
        hazy = hazy.to(device)
        clear = clear.to(device)
        out = model(hazy)
        # to numpy HWC for skimage metrics
        B = out.size(0)
        for i in range(B):
            gt = clear[i].detach().cpu().numpy().transpose(1, 2, 0)
            pr = out[i].detach().cpu().numpy().transpose(1, 2, 0)
            psnrs.append(compare_psnr(gt, pr, data_range=1.0))
            # pick valid win size
            h, w, _ = gt.shape
            win = min(7, h, w)
            if win % 2 == 0:
                win -= 1
            ssims.append(compare_ssim(gt, pr, data_range=1.0, channel_axis=-1, win_size=max(3, win)))
    return float(np.mean(psnrs)), float(np.mean(ssims))


def train(
    generator: nn.Module,
    discriminator: nn.Module,
    train_loader: DataLoader,
    val_loader: DataLoader,
    vgg_extractor: VGGFeatureExtractor,
    num_epochs: int,
    checkpoint_dir: str,
    patience: int = 50,
):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    G, D = generator.to(device), discriminator.to(device)
    gen_loss_fn = GeneratorLoss(vgg_extractor.to(device))

    opt_G = optim.AdamW(G.parameters(), lr=5e-5, betas=(0.9, 0.999))
    opt_D = optim.AdamW(D.parameters(), lr=1e-4, betas=(0.9, 0.999))

    scaler_G = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())
    scaler_D = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())

    best_psnr = -1.0
    no_improve = 0
    os.makedirs(checkpoint_dir, exist_ok=True)

    for epoch in range(1, num_epochs + 1):
        G.train(); D.train()
        for hazy, clear in train_loader:
            hazy = hazy.to(device, non_blocking=True)
            clear = clear.to(device, non_blocking=True)

            # ------------------------
            # Train Discriminator (hinge)
            # ------------------------
            opt_D.zero_grad(set_to_none=True)
            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
                with torch.no_grad():
                    fake = G(hazy)
                real_logits = D(torch.cat([hazy, clear], dim=1))
                fake_logits = D(torch.cat([hazy, fake.detach()], dim=1))
                loss_D = d_hinge_loss(real_logits, fake_logits)
            scaler_D.scale(loss_D).step(opt_D)
            scaler_D.update()

            # ------------------------
            # Train Generator
            # ------------------------
            opt_G.zero_grad(set_to_none=True)
            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
                fake = G(hazy)
                loss_G, _ = gen_loss_fn(hazy, clear, fake, D)
            scaler_G.scale(loss_G).backward()
            scaler_G.step(opt_G)
            scaler_G.update()

        # ------------------------
        # Validation
        # ------------------------
        val_psnr, val_ssim = validate(G, val_loader, device)
        print(f"[Epoch {epoch:03d}] val: PSNR={val_psnr:.3f} SSIM={val_ssim:.4f}")

        if val_psnr > best_psnr:
            best_psnr = val_psnr
            no_improve = 0
            torch.save(G.state_dict(), os.path.join(checkpoint_dir, 'best_generator.pth'))
            torch.save(D.state_dict(), os.path.join(checkpoint_dir, 'best_discriminator.pth'))
        else:
            no_improve += 1
            if no_improve >= patience:
                print("Early stopping (no improvement).")
                break

# ------------------------------------------------------------------------------------
# Entrypoint / example usage
# ------------------------------------------------------------------------------------
if __name__ == "__main__":
    # Paths (update as needed)
    train_hazy_dir = "/content/drive/MyDrive/ITS_standard/hazy"
    train_clear_dir = "/content/drive/MyDrive/ITS_standard/clear1"
    val_hazy_dir   = "/content/drive/MyDrive/SOTS_indoor/hazy"
    val_clear_dir  = "/content/drive/MyDrive/SOTS_indoor/clear1"
    checkpoint_dir = "/content/drive/MyDrive/SOTS_6aug2025"

    # Data
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),  # remains in [0,1]
    ])
    train_ds = HazyDataset(train_hazy_dir, train_clear_dir, transform)
    val_ds   = HazyDataset(val_hazy_dir,   val_clear_dir,   transform)
    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)
    val_loader   = DataLoader(val_ds,   batch_size=8,  shuffle=False, num_workers=2, pin_memory=True)

    # Models
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    G = AdvancedAttentionGenerator(3, 3)
    D = LightweightDiscriminator(6)
    vgg_extractor = VGGFeatureExtractor(device=str(device))

    # Train
    train(G, D, train_loader, val_loader, vgg_extractor, num_epochs=500, checkpoint_dir=checkpoint_dir, patience=50)

"""Testing"""

import os
import time  # For measuring runtime
import numpy as np
from PIL import Image
from skimage.metrics import peak_signal_noise_ratio as compare_psnr, structural_similarity as compare_ssim
import torch
import torch.nn.functional as F
from torchvision.transforms import ToTensor

# Paths for testing set (O-Haze or NH-Haze Dataset)
test_hazy_path = "test hazy folder path"
test_clear_path = "test clear folder path"
save_dehazed_path = "folder path for saving dehazed images"

if not os.path.exists(save_dehazed_path):
    os.makedirs(save_dehazed_path)

# Helper function to load and preprocess images
def load_image(image_path):
    image = Image.open(image_path).convert("RGB")
    original_size = image.size  # Store original size (width, height)
    image = image.resize((256, 256), Image.Resampling.LANCZOS)  # Resize to 256x256 for model input
    image_tensor = ToTensor()(image).unsqueeze(0)  # Convert to tensor and add batch dim
    return image_tensor, original_size

# Helper function to save upsampled dehazed images
def save_image(image_tensor, save_path, original_size):
    image_np = image_tensor.squeeze(0).cpu().numpy().transpose((1, 2, 0))
    image_np = np.clip(image_np, 0, 1) * 255.0
    image_pil = Image.fromarray(image_np.astype('uint8'))
    image_pil = image_pil.resize(original_size, Image.Resampling.LANCZOS)  # Upsample to original size
    image_pil.save(save_path)

# Dataset Loader for Testing (aligning with training dataset loader)
class SOTSTestDataset:
    def __init__(self, hazy_dir, clear_dir):
        self.hazy_paths = sorted([os.path.join(hazy_dir, f) for f in os.listdir(hazy_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])
        self.clear_paths = sorted([os.path.join(clear_dir, f) for f in os.listdir(clear_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])

        if len(self.hazy_paths) != len(self.clear_paths):
            raise ValueError(f"Mismatch in number of hazy ({len(self.hazy_paths)}) and clear ({len(self.clear_paths)}) images. Please check the dataset.")

    def __len__(self):
        return len(self.hazy_paths)

    def __getitem__(self, idx):
        return self.hazy_paths[idx], self.clear_paths[idx]

# Load test dataset
test_dataset = SOTSTestDataset(test_hazy_path, test_clear_path)

# Initialize model and load the best checkpoint
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator = AdvancedAttentionGenerator(3, 3).to(device)

# Load model checkpoint safely
checkpoint_path = "/content/best_generator.pth"
generator.load_state_dict(torch.load(checkpoint_path, map_location=device), strict=False)
generator.eval()

# Initialize metrics and runtime tracker
psnr_list = []
ssim_list = []
runtimes = []  # List to store runtime for each image

# Testing loop
for idx in range(len(test_dataset)):
    hazy_path, clear_path = test_dataset[idx]

    # Load hazy and clear images
    hazy_tensor, original_size = load_image(hazy_path)
    clear_tensor, _ = load_image(clear_path)

    hazy_tensor = hazy_tensor.to(device)
    clear_tensor = clear_tensor.to(device)

    # Measure runtime
    start_time = time.time()

    # Generate dehazed image
    with torch.no_grad():
        dehazed_tensor = generator(hazy_tensor)

    end_time = time.time()
    runtimes.append(end_time - start_time)  # Record runtime

    # Save dehazed image resized to the original size
    hazy_name = os.path.basename(hazy_path)
    save_path = os.path.join(save_dehazed_path, hazy_name)
    save_image(dehazed_tensor, save_path, original_size)

    # Resize clear and dehazed images to the original size for metric computation
    clear_resized = F.interpolate(clear_tensor, size=(original_size[1], original_size[0]), mode='bilinear', align_corners=False)
    dehazed_resized = F.interpolate(dehazed_tensor, size=(original_size[1], original_size[0]), mode='bilinear', align_corners=False)

    # Convert tensors to numpy arrays for metric computation (Ensure correct format)
    clear_np = clear_resized.squeeze(0).cpu().numpy().transpose((1, 2, 0))  # Convert to (H, W, C)
    dehazed_np = dehazed_resized.squeeze(0).cpu().numpy().transpose((1, 2, 0))  # Convert to (H, W, C)

    # Compute PSNR (Data Range should be 1.0, NOT 255, since tensors are normalized)
    psnr = compare_psnr(clear_np, dehazed_np, data_range=1.0)

    # Compute SSIM using multi-channel support
    ssim = compare_ssim(clear_np, dehazed_np, data_range=1.0, channel_axis=-1)

    # Store results
    psnr_list.append(psnr)
    ssim_list.append(ssim)

# Compute average PSNR, SSIM, and runtime
avg_psnr = np.mean(psnr_list)
avg_ssim = np.mean(ssim_list)
max_psnr = np.max(psnr_list)
max_ssim = np.max(ssim_list)
avg_runtime = np.mean(runtimes)

# Print results
print(f"Average PSNR: {avg_psnr:.4f}")
print(f"Average SSIM: {avg_ssim:.4f}")
print(f"Max PSNR: {max_psnr:.4f}")
print(f"Max SSIM: {max_ssim:.4f}")
print(f"Average Runtime per Image: {avg_runtime:.4f} seconds")